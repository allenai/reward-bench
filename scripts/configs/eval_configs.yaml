# This file contains default evaluation parameters assuming access to a single A100-80GB
openbmb/UltraRM-13b:
  model: 'openbmb/UltraRM-13b'
  tokenizer: 'openbmb/UltraRM-13b'
  chat_template: 'openbmb'
  batch_size: 8
  trust_remote_code: False
  dpo: False
OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5:
  model: 'OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5'
  tokenizer: 'OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5'
  chat_template: 'oasst_pythia'
  batch_size: 64
  trust_remote_code: False
  dpo: False
OpenAssistant/oasst-rm-2-pythia-6.9b-epoch-1:
  model: 'OpenAssistant/oasst-rm-2-pythia-6.9b-epoch-1'
  tokenizer: 'OpenAssistant/oasst-rm-2-pythia-6.9b-epoch-1'
  chat_template: 'oasst_pythia'
  batch_size: 16
  trust_remote_code: False
  dpo: False
OpenAssistant/reward-model-deberta-v3-large-v2:
  model: 'OpenAssistant/reward-model-deberta-v3-large-v2'
  tokenizer: 'OpenAssistant/reward-model-deberta-v3-large-v2'
  chat_template: 'raw'
  batch_size: 64
  trust_remote_code: False
  dpo: False
weqweasdas/hh_rlhf_rm_open_llama_3b:
  model: 'weqweasdas/hh_rlhf_rm_open_llama_3b'
  tokenizer: 'weqweasdas/hh_rlhf_rm_open_llama_3b'
  chat_template: 'Robin'
  batch_size: 64
  trust_remote_code: False
  dpo: False
llm-blender/PairRM-hf:
  model: 'llm-blender/PairRM-hf'
  tokenizer: 'llm-blender/PairRM-hf'
  chat_template: 'tulu'
  batch_size: 64
  trust_remote_code: False
  dpo: False
berkeley-nest/Starling-RM-7B-alpha:
  model: 'berkeley-nest/Starling-RM-7B-alpha'
  tokenizer: 'meta-llama/Llama-2-7b-chat-hf'
  chat_template: 'llama-2'
  batch_size: 16
  trust_remote_code: False
  dpo: False
stanfordnlp/SteamSHP-flan-t5-xl:
  model: 'stanfordnlp/SteamSHP-flan-t5-xl'
  tokenizer: 'stanfordnlp/SteamSHP-flan-t5-xl'
  chat_template: 'tulu'
  batch_size: 32
  trust_remote_code: False
  dpo: False
stanfordnlp/SteamSHP-flan-t5-large:
  model: 'stanfordnlp/SteamSHP-flan-t5-large'
  tokenizer: 'stanfordnlp/SteamSHP-flan-t5-large'
  chat_template: 'tulu'
  batch_size: 32
  trust_remote_code: False
  dpo: False
PKU-Alignment/beaver-7b-v1.0-reward:
  model: 'PKU-Alignment/beaver-7b-v1.0-reward'
  tokenizer: 'PKU-Alignment/beaver-7b-v1.0-reward'
  chat_template: 'pku-align'
  batch_size: 16
  trust_remote_code: False
  dpo: False
PKU-Alignment/beaver-7b-v1.0-cost:
  model: 'PKU-Alignment/beaver-7b-v1.0-cost'
  tokenizer: 'PKU-Alignment/beaver-7b-v1.0-cost'
  chat_template: 'pku-align'
  batch_size: 16
  trust_remote_code: False
  dpo: False
IDEA-CCNL/Ziya-LLaMA-7B-Reward:
  model: 'IDEA-CCNL/Ziya-LLaMA-7B-Reward'
  tokenizer: 'IDEA-CCNL/Ziya-LLaMA-7B-Reward'
  chat_template: 'Ziya'
  batch_size: 16
  trust_remote_code: True
  dpo: False
Nexusflow/Starling-RM-34B:
  model: 'Nexusflow/Starling-RM-34B'
  tokenizer: '01-ai/Yi-34B-Chat'
  chat_template: 'Yi-34b-chat'
  num_gpus: 2
  batch_size: 2
  trust_remote_code: False
  dpo: False
stabilityai/stablelm-zephyr-3b:
  ref_model: stabilityai/stablelm-3b-4e1t
  tokenizer: stabilityai/stablelm-zephyr-3b
  chat_template:
  batch_size: 12
  trust_remote_code: False
  dpo: True
stabilityai/stablelm-2-zephyr-1_6b:
  ref_model: stabilityai/stablelm-2-1_6b
  tokenizer: stabilityai/stablelm-2-zephyr-1_6b
  chat_template:
  batch_size: 6
  trust_remote_code: True
  dpo: True
HuggingFaceH4/zephyr-7b-beta:
  ref_model: HuggingFaceH4/mistral-7b-sft-beta
  tokenizer: HuggingFaceH4/zephyr-7b-beta
  chat_template:
  batch_size: 4
  trust_remote_code: False
  dpo: True
HuggingFaceH4/zephyr-7b-alpha:
  ref_model: HuggingFaceH4/mistral-7b-sft-alpha
  tokenizer: HuggingFaceH4/zephyr-7b-alpha
  chat_template:
  batch_size: 4
  trust_remote_code: False
  dpo: True
Qwen/Qwen1.5-0.5B-Chat:
  ref_model: Qwen/Qwen1.5-0.5B
  tokenizer: Qwen/Qwen1.5-0.5B-Chat
  chat_template:
  batch_size: 6
  trust_remote_code: False
  dpo: True
Qwen/Qwen1.5-1.8B-Chat:
  ref_model: Qwen/Qwen1.5-1.8B
  tokenizer: Qwen/Qwen1.5-1.8B-Chat
  chat_template:
  batch_size: 3
  trust_remote_code: False
  dpo: True
Qwen/Qwen1.5-4B-Chat:
  ref_model: Qwen/Qwen1.5-4B
  tokenizer: Qwen/Qwen1.5-4B-Chat
  chat_template:
  batch_size: 2
  trust_remote_code: False
  dpo: True
Qwen/Qwen1.5-7B-Chat:
  ref_model: Qwen/Qwen1.5-7B
  tokenizer: Qwen/Qwen1.5-7B-Chat
  chat_template:
  batch_size: 2
  trust_remote_code: False
  dpo: True
Qwen/Qwen1.5-14B-Chat:
  ref_model: Qwen/Qwen1.5-14B
  tokenizer: Qwen/Qwen1.5-14B-Chat
  chat_template:
  batch_size: 2
  num_gpus: 2
  trust_remote_code: False
  dpo: True
Qwen/Qwen1.5-72B-Chat:
  ref_model: Qwen/Qwen1.5-72B
  tokenizer: Qwen/Qwen1.5-72B-Chat
  chat_template:
  batch_size: 1
  num_gpus: 4
  trust_remote_code: False
  dpo: True
mistralai/Mixtral-8x7B-Instruct-v0.1:
  ref_model: mistralai/Mixtral-8x7B-v0.1
  tokenizer: mistralai/Mixtral-8x7B-Instruct-v0.1
  chat_template:
  batch_size: 1
  num_gpus: 4
  trust_remote_code: False
  dpo: True
NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO:
  ref_model: NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT
  tokenizer: NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO
  chat_template:
  batch_size: 1
  num_gpus: 4
  trust_remote_code: True
  dpo: True
NousResearch/Nous-Hermes-2-Mistral-7B-DPO:
  ref_model: teknium/OpenHermes-2.5-Mistral-7B
  tokenizer: NousResearch/Nous-Hermes-2-Mistral-7B-DPO
  chat_template:
  batch_size: 4
  trust_remote_code: False
  dpo: True
HuggingFaceH4/zephyr-7b-gemma-v0.1:
  ref_model: HuggingFaceH4/zephyr-7b-gemma-sft-v0.1
  tokenizer: HuggingFaceH4/zephyr-7b-gemma-v0.1
  chat_template:
  batch_size: 2
  trust_remote_code: False
  dpo: True
allenai/tulu-2-dpo-70b:
  ref_model: allenai/tulu-2-70b
  tokenizer: allenai/tulu-2-dpo-70b
  chat_template: tulu
  num_gpus: 4
  batch_size: 2
  trust_remote_code: False
  dpo: True
allenai/tulu-2-dpo-13b:
  ref_model: allenai/tulu-2-13b
  tokenizer: allenai/tulu-2-dpo-13b
  chat_template: tulu
  num_gpus: 2
  batch_size: 2
  trust_remote_code: False
  dpo: True
allenai/tulu-2-dpo-7b:
  ref_model: allenai/tulu-2-7b
  tokenizer: allenai/tulu-2-dpo-7b
  chat_template: tulu
  batch_size: 2
  trust_remote_code: False
  dpo: True
allenai/OLMo-7B-Instruct:
  ref_model: allenai/OLMo-7B-SFT
  tokenizer: allenai/OLMo-7B-Instruct
  chat_template:
  batch_size: 2
  trust_remote_code: True
  dpo: True
# Added March 21st 2024
weqweasdas/RM-Gemma-2B:
  model: weqweasdas/RM-Gemma-2B
  tokenizer: weqweasdas/RM-Gemma-2B
  chat_template: # empty for tokenizer
  batch_size: 16
  trust_remote_code: False
  dpo: False
weqweasdas/RM-Gemma-7B:
  model: weqweasdas/RM-Gemma-7B
  tokenizer: weqweasdas/RM-Gemma-7B
  chat_template: # empty for tokenizer
  batch_size: 16
  trust_remote_code: False
  dpo: False
weqweasdas/RM-Gemma-7B-4096:
  model: weqweasdas/RM-Gemma-7B-4096
  tokenizer: weqweasdas/RM-Gemma-7B-4096
  chat_template: # empty for tokenizer
  batch_size: 16
  trust_remote_code: False
  dpo: False
Ray2333/reward-model-Mistral-7B-instruct-Unified-Feedback:
  model: Ray2333/reward-model-Mistral-7B-instruct-Unified-Feedback
  tokenizer: Ray2333/reward-model-Mistral-7B-instruct-Unified-Feedback
  chat_template: # empty for tokenizer
  batch_size: 16
  trust_remote_code: False
  dpo: False
hendrydong/Mistral-RM-for-RAFT-GSHF-v0:
  model: hendrydong/Mistral-RM-for-RAFT-GSHF-v0
  tokenizer: hendrydong/Mistral-RM-for-RAFT-GSHF-v0
  chat_template: # empty for tokenizer
  batch_size: 16
  trust_remote_code: False
  dpo: False
weqweasdas/RM-Mistral-7B:
  model: weqweasdas/RM-Mistral-7B
  tokenizer: weqweasdas/RM-Mistral-7B
  chat_template: # empty for tokenizer
  batch_size: 16
  trust_remote_code: False
  dpo: False
# Added March 25th 2024 KTO / Archangel models follow
ContextualAI/archangel_sft-kto_llama7b:
  model: ContextualAI/archangel_sft-kto_llama7b
  ref_model: ContextualAI/archangel_sft_llama7b
  tokenizer: ContextualAI/archangel_sft-kto_llama7b
  chat_template: tulu
  batch_size: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-dpo_llama7b:
  model: ContextualAI/archangel_sft-dpo_llama7b
  ref_model: ContextualAI/archangel_sft_llama7b
  tokenizer: ContextualAI/archangel_sft-dpo_llama7b
  chat_template: tulu
  batch_size: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-kto_llama13b:
  model: ContextualAI/archangel_sft-kto_llama13b
  ref_model: ContextualAI/archangel_sft_llama13b
  tokenizer: ContextualAI/archangel_sft-kto_llama13b
  chat_template: tulu
  batch_size: 2
  num_gpus: 2
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-dpo_llama13b:
  model: ContextualAI/archangel_sft-dpo_llama13b
  ref_model: ContextualAI/archangel_sft_llama13b
  tokenizer: ContextualAI/archangel_sft-dpo_llama13b
  chat_template: tulu
  batch_size: 2
  num_gpus: 2
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-kto_llama30b:
  model: ContextualAI/archangel_sft-kto_llama30b
  ref_model: ContextualAI/archangel_sft_llama30b
  tokenizer: ContextualAI/archangel_sft-kto_llama30b
  chat_template: tulu
  batch_size: 1
  num_gpus: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-dpo_llama30b:
  model: ContextualAI/archangel_sft-dpo_llama30b
  ref_model: ContextualAI/archangel_sft_llama30b
  tokenizer: ContextualAI/archangel_sft-dpo_llama30b
  chat_template: tulu
  batch_size: 1
  num_gpus: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-dpo_pythia1-4b:
  model: ContextualAI/archangel_sft-dpo_pythia1-4b
  ref_model: ContextualAI/archangel_sft_pythia1-4b
  tokenizer: ContextualAI/archangel_sft-dpo_pythia1-4b
  chat_template: tulu
  batch_size: 6
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-kto_pythia1-4b:
  model: ContextualAI/archangel_sft-kto_pythia1-4b
  ref_model: ContextualAI/archangel_sft_pythia1-4b
  tokenizer: ContextualAI/archangel_sft-kto_pythia1-4b
  chat_template: tulu
  batch_size: 6
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-dpo_pythia2-8b:
  model: ContextualAI/archangel_sft-dpo_pythia2-8b
  ref_model: ContextualAI/archangel_sft_pythia2-8b
  tokenizer: ContextualAI/archangel_sft-dpo_pythia2-8b
  chat_template: tulu
  batch_size: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-kto_pythia2-8b:
  model: ContextualAI/archangel_sft-kto_pythia2-8b
  ref_model: ContextualAI/archangel_sft_pythia2-8b
  tokenizer: ContextualAI/archangel_sft-kto_pythia2-8b
  chat_template: tulu
  batch_size: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-dpo_pythia6-9b:
  model: ContextualAI/archangel_sft-dpo_pythia6-9b
  ref_model: ContextualAI/archangel_sft_pythia6-9b
  tokenizer: ContextualAI/archangel_sft-dpo_pythia6-9b
  chat_template: tulu
  batch_size: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-kto_pythia6-9b:
  model: ContextualAI/archangel_sft-kto_pythia6-9b
  ref_model: ContextualAI/archangel_sft_pythia6-9b
  tokenizer: ContextualAI/archangel_sft-kto_pythia6-9b
  chat_template: tulu
  batch_size: 4
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-dpo_pythia12-0b:
  model: ContextualAI/archangel_sft-dpo_pythia12-0b
  ref_model: ContextualAI/archangel_sft_pythia12-0b
  tokenizer: ContextualAI/archangel_sft-dpo_pythia12-0b
  chat_template: tulu
  batch_size: 4
  num_gpus: 2
  trust_remote_code: False
  dpo: True
ContextualAI/archangel_sft-kto_pythia12-0b:
  model: ContextualAI/archangel_sft-kto_pythia12-0b
  ref_model: ContextualAI/archangel_sft_pythia12-0b
  tokenizer: ContextualAI/archangel_sft-kto_pythia12-0b
  chat_template: tulu
  batch_size: 4
  num_gpus: 2
  trust_remote_code: False
  dpo: True
0-hero/Matter-0.1-7B-DPO-preview:
  model: 0-hero/Matter-0.1-7B-DPO-preview
  ref_model: 0-hero/Matter-0.1-7B
  tokenizer: 0-hero/Matter-0.1-7B-DPO-preview
  chat_template: # none for tokenizer
  batch_size: 4
  trust_remote_code: False
  dpo: True
0-hero/Matter-0.1-7B-boost-DPO-preview:
  model: 0-hero/Matter-0.1-7B-boost-DPO-preview
  ref_model: 0-hero/Matter-0.1-7B-boost
  tokenizer: 0-hero/Matter-0.1-7B-boost-DPO-preview
  chat_template: # none for tokenizer
  batch_size: 4
  trust_remote_code: False
  dpo: True
openbmb/Eurus-RM-7b:
  model: openbmb/Eurus-RM-7b
  tokenizer: openbmb/Eurus-RM-7b
  chat_template: mistral
  batch_size: 16
  trust_remote_code: True
  dpo: False
openbmb/Eurus-7b-kto:
  model: openbmb/Eurus-7b-kto
  ref_model: openbmb/Eurus-7b-sft
  tokenizer: openbmb/Eurus-7b-kto
  chat_template: mistral
  batch_size: 4
  trust_remote_code: True
  dpo: True
Qwen/Qwen1.5-MoE-A2.7B-Chat:
  model: Qwen/Qwen1.5-MoE-A2.7B-Chat
  ref_model: Qwen/Qwen1.5-MoE-A2.7B
  tokenizer: Qwen/Qwen1.5-MoE-A2.7B-Chat
  chat_template: # none for tokenizer
  num_gpus: 2
  batch_size: 4
  trust_remote_code: False
  dpo: True
stabilityai/stable-code-instruct-3b:
  model: stabilityai/stable-code-instruct-3b
  ref_model: stabilityai/stable-code-3b
  tokenizer: stabilityai/stable-code-instruct-3b
  chat_template: # none for tokenizer
  batch_size: 4
  trust_remote_code: True
  dpo: True
HuggingFaceH4/starchat2-15b-v0.1:
  model: HuggingFaceH4/starchat2-15b-v0.1
  ref_model: HuggingFaceH4/starchat2-15b-sft-v0.1
  tokenizer: HuggingFaceH4/starchat2-15b-v0.1
  chat_template: # none for tokenizer
  batch_size: 4
  num_gpus: 2
  trust_remote_code: False
  dpo: True